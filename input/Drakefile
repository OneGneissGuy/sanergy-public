
wget_unzip()
        mkdir -p $(dirname $OUTPUT0)
        mkdir -p $(dirname $OUTPUT1)
        wget --output-document="$OUTPUT0" "$URL"
        unzip -o "$OUTPUT0" -d $(dirname $OUTPUT1)

extract_shapefiles_fromzip()
        DIRNAME=$(dirname $OUTPUT)
        BASENAME=$(basename $OUTPUT | sed 's/.shp//')ls /
        unzip -joDD $INPUT */$BASENAME.* -d $DIRNAME

import_shapefile()
        BASENAME=$(basename "$INPUT" | sed 's/.shp//')
        BASENAME_LOWERCASE=$(echo $BASENAME | tr -d ':' | tr [:upper:] [:lower:])
        shp2pgsql -d -s 2274 "$INPUT" shapefiles."$BASENAME_LOWERCASE" | psql -q && touch $OUTPUT

BOX_FOLDER:=Sanergy/data

;;; SHAPEFILES ;;;
psql/input/shapefiles/SanergyFresh_Life_mapping_areas <- data/input/shapefiles/SanergyFresh_Life_mapping_areas.kml
	ogr2ogr -f "PostgreSQL" PG:"host=$PGHOST user=$PGUSER dbname=$PGDATABASE password=$PGPASSWORD active_schema=shapefiles" $INPUT
	touch $OUTPUT
psql/input/shapefiles/kibera_public <- data/input/shapefiles/kibera_public.kml
	ogr2ogr -f "PostgreSQL" PG:"host=$PGHOST user=$PGUSER dbname=$PGDATABASE password=$PGPASSWORD active_schema=shapefiles_kibera" $INPUT
	touch $OUTPUT
psql/input/shapefiles/mathare_public <- data/input/shapefiles/mathare_public.kml
	ogr2ogr -f "PostgreSQL" PG:"host=$PGHOST user=$PGUSER dbname=$PGDATABASE password=$PGPASSWORD active_schema=shapefiles_mathare" $INPUT
	touch $OUTPUT
psql/input/shapefiles/mukuru_public <- data/input/shapefiles/mukuru_public.kml
	ogr2ogr -f "PostgreSQL" PG:"host=$PGHOST user=$PGUSER dbname=$PGDATABASE password=$PGPASSWORD active_schema=shapefiles_mukuru" $INPUT
	touch $OUTPUT

psql/input/shapefiles/schema <- [-timecheck]
	echo "create schema if not exists shapefiles;" | psql && mkdir -p $(dirname $OUTPUT) && touch $OUTPUT

psql/input/shapefiles/watsan_Mathare <- $[BOX_FOLDER]/'Map Kibera/Mathare - watsan-shapefile/watsan.shp', psql/input/shapefiles/schema [method:import_shapefile]
psql/input/shapefiles/watsan_Mukuru <- $[BOX_FOLDER]/'Map Kibera/MKR - watsan-shapefile/watsan.shp', psql/input/shapefiles/schema [method:import_shapefile]
psql/input/shapefiles/boundary_Kibera <- $[BOX_FOLDER]/'Map Kibera/Shapefiles/kibera_boundary-shapefile/Boundary.shp', psql/input/shapefiles/schema [method:import_shapefile]
psql/input/shapefiles/boundary_Mathare <- $[BOX_FOLDER]/'Map Kibera/Shapefiles/Mathare_boundary-shapefile/Boundary.shp', psql/input/shapefiles/schema [method:import_shapefile]
psql/input/shapefiles/boundary_Mukuru <- $[BOX_FOLDER]/'Map Kibera/Shapefiles/Mukuru_boundary-shapefile/Boundary.shp', psql/input/shapefiles/schema [method:import_shapefile]


;;; IPA Survey ;;;
$[BOX_FOLDER]/IPA/IPA_data_incomplete.csv <- input/IPA_data_incomplete.R, $[BOX_FOLDER]/IPA/IPA_data_incomplete.sav
	R CMD BATCH $INPUT0
$[BOX_FOLDER]/IPA/IPA_data_incomplete_NAreplaced.csv <- $[BOX_FOLDER]/IPA/IPA_data_incomplete.csv
	sed -E 's~("N/A"|NA)~~g' $INPUT > $OUTPUT
psql/input/ipa_data_incomplete_NAreplaced <- input/ipa_data_incomplete.sql, $[BOX_FOLDER]/IPA/IPA_data_incomplete_NAreplaced.csv [method:psql]

;;; Collection Schedule ;;;
$[BOX_FOLDER]/wheelCut.csv, $[BOX_FOLDER]/truckCut.csv, $[BOX_FOLDER]/tukCut.csv <- input/extract_schedule.sh, $[BOX_FOLDER]/Logistics_schedule.xlsx
	bash $INPUT0

;;; School by Route ;;;
$[BOX_FOLDER]/school_by_route.csv <- $[BOX_FOLDER]/Logistics_schedule.xlsx
	in2csv --sheet "SF_check" $[BOX_FOLDER]/Logistics_schedule.xlsx | csvcut -c 1-25 > $[BOX_FOLDER]/school_by_route.csv

psql/input/collection_schedule <- input/CollectionSchedule_input.sql, $[BOX_FOLDER]/AllCasesAreaToiletID.csv, $[BOX_FOLDER]/school_by_route.csv [method:psql]

;;; Model tables ;;;
psql/input/model_tables <- input/model_reporting_tables.sql, $[BOX_FOLDER]/AllCasesAreaToiletID.csv [method:psql]

;;; Toilet Coordinates ;;;
psql/input/toilet_coordinates <- input/ToiletCoords_input.sql, $[BOX_FOLDER]/ToiletCoords.csv [method:psql]

;;; Route Schedule Since Feb 2016 ;;;
psql/input/schedule_routes <- input/schedule_routes.sql, $[BOX_FOLDER]/Route_Master_All_Dates.csv [method:psql]


;;; WEATHER ;;;
$[BOX_FOLDER]/weather/weather_download_jkia <- input/weather/weather_download.sh
        DIRNAME=$(dirname $OUTPUT)
        bash $INPUT $DIRNAME '637400' '99999' && touch $OUTPUT
$[BOX_FOLDER]/weather/weather_master.csv <- input/weather/weather_schema.csv, $[BOX_FOLDER]/weather/weather_download_jkia
        gunzip -c $(dirname $OUTPUT)/*.gz |
        sed 's/-9999/     /g' |
        in2csv -H -s $INPUT0 > $OUTPUT
psql/input/weather <- input/weather/weather.sql, $[BOX_FOLDER]/weather/weather_master.csv [method:psql]

;;; CONVERSION FROM MSSQL ;;;
psql/input/dssg_dump <- $[BOX_FOLDER]/'Sanergy - Fresh Life Toilet Waste DataBase.bak'
	python input/mssql2postgres.py -m mssql_profile -p default_profile && touch $OUTPUT || echo "ERROR: Must have SQL Server instance running with backup file loaded. See input/README.md for details"

;;; FURTHER PROCESSING ;;;
psql/input/toilethistory <- input/geo_spatial_toilets_sham.sql, $[BOX_FOLDER]/weather/weather_master.csv [method:psql]

psql/input/toiletcollection1 <- premodeling/ProcessCollectionsData.py, psql/input/toilethistory, psql/input/dssg_dump
	python premodeling/ProcessCollectionsData.py && touch $OUTPUT

psql/input/toiletdensity <- input/geo_spatial_toilets.sql, psql/input/toiletcollection1 [method:psql]

psql/input/toiletcollection2 <- premodeling/ProcessCollectionsData.py, psql/input/toiletdensity, psql/input/dssg_dump
	python premodeling/ProcessCollectionsData.py && touch $OUTPUT
