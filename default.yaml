#####################################################
#          UChicago Data Science for Social Good:   #
#              Optimizing Waste Collection          #
#               from Portable Sanitation            #
#####################################################

setup:
    run_features: True
    collection_remainder_threshold: [50] #[50,40,30,20,10] #Keep [] if you want to loop over 0..100

############################
# Database column names    #
############################

cols:
  toiletname: "ToiletID" #the name of the toilet / toilet identifier
  date: "Collection_Date" # date / date identifier
  route: "SubAreaName" #Which area/route to define as an allocation unit in the staffing model
  feces: "FecesContainer_percent" #How full the container will be
  urine: "UrineContainer_percent"
  feces_collect: "" #Should the toilet be collected?
  urine_collect: ""
  #WASTE = {"feces": FECES, "urine": URINE} # Either feces or urine
  #COLLECT = {"feces": FECES_COLLECT, "urine": URINE_COLLECT}


#################################
# Feature/response generation parameters #
#################################

#Connection parameters
db:
    #connection: conn
    table: 'toiletcollection'
    database: 'premodeling'
#The model matrix
Xy:
    response_f:
        #variable: 'Feces_kg_day'
        #split: []
        #type: 'binary'
        variable: 'FecesContainer_percent'
        split: []
        #  and: [['>','100']]
    response_u:
        variable: 'UrineContainer_percent'
        split: []
    features:
      #Total_Waste_kg_day: []
      #UrineContainer_percent: []
      #sd_wind_speed_rate: []
      #sd_sea_level_pressure: []
      #sd_precipitation_6hr: []
      #sd_air_temp: []
      #min_wind_speed_rate: []
      #min_sea_level_pressure: []
      #min_precipitation_6hr: []
      #min_air_temp: []
      #max_wind_speed_rate: []
      #max_sea_level_pressure: []
      #max_precipitation_6hr: []
      #max_air_temp: []
      #mean_wind_speed_rate: []
      #mean_sea_level_pressure: []
      #mean_precipitation_6hr: []
      #mean_air_temp: []
      SubAreaName: []
      School_Closure: []
      #Route_Name: []       #OpportunityName: []
      OpeningTime: []
      ClosingTime: []
      #Missed_Collection_Code: []
      FranchiseType: []
      50m: []
      #mean50m: []
      CasePriorWeek: []
      DaysOpenInWeek: []
      month: []
    unique:
      ToiletID: []
      Collection_Date: []
    lagged:
        FecesContainer_percent:
            function: 'lag'
            rows: [1,2,3]
        UrineContainer_percent:
            function: 'lag'
            rows: [1,2,3]
              #Urine_kg_day:
      #    function: 'lag'
      #    rows: [1,2,3]
          #rows: [1,2,3]

############################
# Model parameters         #
############################
#model: ["LinearRegression", "RandomForest", "Autoregression", "SimpleModel"]
#model: ['LinearRegression', "RandomForest",  'Lasso', 'ElasticNet', 'SVR', 'SGDClassifier'] #'AR'
model: ['LinearRegression']

parameters:
  RandomForest:
    n_estimators: [10]
    max_depth: [3]
    max_features: [8]
    criterion: ['entropy']
    min_samples_split: [10]
    # n_estimators: [1, 10, 25, 50, 100]  # [1000, 10000]
    # max_depth: [1, 3, 5, 10, 20]  # 50, 100
    # max_features: ['sqrt', 'log2']  # [2, 4, 8, 16, "auto"]
    # criterion: ['gini', 'entropy']
    # min_samples_split: [2, 5, 10]
  AR:
    maxlag: [3]
    #maxlag: [5, 10]
  LinearRegression:
    dummy: [1] #A fake parameter making sure that we loop over this model.
  Lasso:
    alpha: [0.1] # The alpha parameter controls the degree of sparsity of the coefficients estimated.
  ElasticNet:
    alpha: [0.1]
    l1_ratio: [0.5]
  SVR: # http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html
    C: [1.0] # Penalty parameter C of the error term.
    epsilon: [0.1] # Epsilon in the epsilon-SVR model. It specifies the epsilon-tube within which no penalty is associated in the training loss function with points predicted within a distance epsilon from the actual value.
    kernel: ['rbf'] #Specifies the kernel type to be used in the algorithm. It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or a callable. If none is given, 'rbf' will be used. If a callable is given it is used to precompute the kernel matrix.
  SGDClassifier:
    loss: ['hinge']
    penalty: ['l1']
    epsilon: [0.1]
    l1_ratio: [0.5]
cv:
  start_date: '2016-03-01'
  end_date: '2016-05-01'
  train_on: 14
  test_on: 7
  fake_freq: '3W'

#############################
# Implementation parameters #
#############################
implementation:
  loss: ['0-1'] #["L2", "L1"]
  prediction_horizon: [7] #How many days
  prediction_weekday_start: [0] #Which day of the week do we recompute the schedule? 0=Mon, 7=Sun. Applicable for weekly or multiple-thereof schedules.
  aggregation_measure: ["mean"] #A measure to use to aggregate the losses across different folds. Since different experiments may have different numbers of folds, should be a probability measure.
  #thresholds: {'meanlow':23, 'stdlow':100, 'meanmed':40, 'stdmed':10}  # static model parameters

#############################
# Staffing parameters       #
#############################
staffing:
    active: True #Should we compute the staffing?
    N: 30 #number of available workers
    W: 2000 #weight limit per worker per day. 2000 = 20*100 (2000 toilets)
    NR: 2 #minimum number of workers required per route (assume 2, but in fact some need 3 -> fix later)
    D: 5 #day limit of workdays per week per worker
