#####################################################
#          UChicago Data Science for Social Good:   #
#              Optimizing Waste Collection          #
#               from Portable Sanitation            #
#####################################################

setup:
    run_features: False
    collection_remainder_threshold: [50,40,30,20,10] #Keep [] if you want to loop over 0..100

############################
# Database column names    #
############################

cols:
  toiletname: "ToiletID" #the name of the toilet / toilet identifier
  date: "Collection_Date" # date / date identifier
  route: "Area" #Which area/route to define as the allocation unit in the staffing model
  feces: "FecesContainer_percent" #How full the container will be
  urine: "UrineContainer_percent"
  feces_collect: "" #Should the toilet be collected?
  urine_collect: ""
  #WASTE = {"feces": FECES, "urine": URINE} # Either feces or urine
  #COLLECT = {"feces": FECES_COLLECT, "urine": URINE_COLLECT}


#################################
# Feature/response generation parameters #
#################################

#Connection parameters
db:
    #connection: conn
    table: 'toiletcollection'
    database: 'premodeling'
#The model matrix
Xy:
    response_f:
        #variable: 'Feces_kg_day'
        #split: []
        #type: 'binary'
        variable: 'FecesContainer_percent'
        split: []
        #  and: [['>','100']]
    response_u:
        variable: 'UrineContainer_percent'
        split: []
    features:
      #Total_Waste_kg_day: []
      UrineContainer_percent: []
      sd_wind_speed_rate: []
      sd_sea_level_pressure: []
      sd_precipitation_6hr: []
      sd_air_temp: []
      min_wind_speed_rate: []
      min_sea_level_pressure: []
      min_precipitation_6hr: []
      min_air_temp: []
      max_wind_speed_rate: []
      max_sea_level_pressure: []
      max_precipitation_6hr: []
      max_air_temp: []
      mean_wind_speed_rate: []
      mean_sea_level_pressure: []
      mean_precipitation_6hr: []
      mean_air_temp: []
      SubAreaName: []
      Area: []
      School_Closure: []
      Route_Name: []      
      OpportunityName: []
      OpeningTime: []
      ClosingTime: []
      Missed_Collection_Code: []
      FranchiseType: []
      average_50m_1days_Feces_kg_day: []
      average_50m_1days_Urine_kg_day: []
      average_50m_1days_distance: []
      average_50m_7days_Feces_kg_day: []
      average_50m_7days_Urine_kg_day: []
      average_50m_7days_distance: []
      average_5m_1days_Feces_kg_day: []
      average_5m_1days_Urine_kg_day: []
      average_5m_1days_distance: []
      average_5m_7days_Feces_kg_day: []
      average_5m_7days_Urine_kg_day: []
      average_5m_7days_distance: []
      collections_50m_1days_Feces_kg_day: []
      collections_50m_1days_Urine_kg_day: []
      collections_50m_7days_Feces_kg_day: []
      collections_50m_7days_Urine_kg_day: []
      collections_5m_1days_Feces_kg_day: []
      collections_5m_1days_Urine_kg_day: []
      collections_5m_7days_Feces_kg_day: []
      collections_5m_7days_Urine_kg_day: []
      CasePriorWeek: []
      DaysOpenInWeek: []
      month: []
    unique:
      ToiletID: []
      Collection_Date: []
    lagged:
        FecesContainer_percent:
            function: 'lag'
            rows: [1,2,3]
        UrineContainer_percent:
            function: 'lag'
            rows: [1,2,3]
              #Urine_kg_day:
      #    function: 'lag'
      #    rows: [1,2,3]
          #rows: [1,2,3]

############################
# Model parameters         #
############################
#model: ["LinearRegression", "RandomForest", "Autoregression", "SimpleModel"] 'SGDRegressor',
#model: ['StaticModel']
model: ['RandomForest',  'Lasso', 'ElasticNet', 'SVR']

#pickle_store: "/mnt/data"
pickle_store: "/mnt/data/sanergy/output"

parameters:
  RandomForest:
    n_estimators: [120,300,500,800,1200]
    max_depth: [5,8,15,25,30]
    max_features: ['sqrt','log2']
    criterion: ['entropy']
    min_samples_split: [10]
    # n_estimators: [1, 10, 25, 50, 100]  # [1000, 10000]
    # max_depth: [1, 3, 5, 10, 20]  # 50, 100
    # max_features: ['sqrt', 'log2']  # [2, 4, 8, 16, "auto"]
    # criterion: ['gini', 'entropy']
    # min_samples_split: [2, 5, 10]
    # AR:
    #   maxlag: [3]
    #   #maxlag: [5, 10]
  StaticModel:
    parameters:
      meanlow: [23]
      stdlow: [100]
      meanmed: [40]
      stdmed: [10]
  AdvancedStaticModel:
    parameters:
      meanlow: [23]
      stdlow: [100]
      meanmed: [40]
      stdmed: [10]
  LinearRegression:
    dummy: [1] #A fake parameter making sure that we loop over this model.
  Lasso:
    normalize: [True, False]
    alpha: [0.1, 1.0, 10] # The alpha parameter controls the degree of sparsity of the coefficients estimated.
  ElasticNet:
    alpha: [0.1, 1.0, 10]
    l1_ratio: [0.1, 0.5, 1.0]
  SVR: # http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html
    C: [0.001, 0.01, 0.1, 1.0, 10, 100, 1000] # Penalty parameter C of the error term.
    epsilon: [0.001, 0.01, 0.1, 1.0] # Epsilon in the epsilon-SVR model. It specifies the epsilon-tube within which no penalty is associated in the training loss function with points predicted within a distance epsilon from the actual value.
    kernel: ['rbf', 'linear', 'poly'] #Specifies the kernel type to be used in the algorithm. It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or a callable. If none is given, 'rbf' will be used. If a callable is given it is used to precompute the kernel matrix.
  # SGDRegressor:
  #   loss: ['squared_loss']
  #   penalty: ['elasticnet']
  #   l1_ratio: [0.15]
cv:
  start_date: '2016-02-01'
  end_date: '2016-05-01'
  train_on: 14
  test_on: 7
  fake_freq: '1W'

#############################
# Implementation parameters #
#############################
implementation:
  #loss: ['0-1'] #["L2", "L1"]
  prediction_horizon: [7] #How many days
  prediction_weekday_start: [0] #Which day of the week do we recompute the schedule? 0=Mon, 7=Sun. Applicable for weekly or multiple-thereof schedules.
  aggregation_measure: ["mean"] #A measure to use to aggregate the losses across different folds. Since different experiments may have different numbers of folds, should be a probability measure.
  #thresholds: {'meanlow':23, 'stdlow':100, 'meanmed':40, 'stdmed':10}  # static model parameters

#############################
# Staffing parameters       #
#############################
staffing:
    active: True #Should we compute the staffing?
    N: 100 #number of available workers
    W: 2000 #weight limit per worker per day. 2000 = 20*100 (2000 toilets)
    NR: 2 #minimum number of workers required per route (assume 2, but in fact some need 3 -> fix later)
    D: 5 #day limit of workdays per week per worker
